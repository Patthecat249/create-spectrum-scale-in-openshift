---
- name: "{{ lookup('pipe','date \"+%Y-%m-%d %H-%M-%S\"') }} | Playbook Install Requirement for Spectrum-Scale"
  hosts: spectrumscale
  vars_files:
    - "./vars/vars.yaml"
  gather_facts: false
  tasks:
    - name: "01 - Add EPEL-Release-Repo"
      yum:
        name: epel-release.noarch
        state: present

# Install Software packages
    - name: "02 - Install necassary software programs"
      become: "true"
      yum:
        name:
          - bind-utils.x86_64
          - nfs-utils.x86_64
          - net-tools
          - chrony.x86_64
          - cpp.x86_64
          - gcc.x86_64
          - gcc-c++.x86_64
          - python3
          - elfutils.x86_64
          - elfutils-devel.x86_64
        state: "present"

    - name: "03 - Create Shell-Script"
      template:
        src: "spectrumscale-install-deploy.sh.j2"
        dest: "{{dir_root}}spectrumscale-install-deploy.sh"
        mode: "0755"
      delegate_to: 127.0.0.1
      tags:
        - retry

    - name: "04 - Check if folder {{ dir_root }} exists"
      stat:
        path: "{{ dir_root }}"
      register: folder_details

    # - name: "04 - DEBUG"
    #   debug:
    #     msg: "{{ folder_details }}"

    - name: "05 - Create Directoy {{ dir_root }}"
      file:
        recurse: "true"
        path: "{{ item }}"
        state: "directory"
      with_items:
        - "{{ dir_root }}"
        - "{{ sps_mountpoint_fs1 }}"
      when:
        - not folder_details.stat.exists
    
    - name: "06 - Spectrum-Scale-Mount-Verzeichnis erstellen"
      file:
        recurse: "true"
        path: "{{ item }}"
        state: "directory"
      with_items:
        - "{{ dest_nas_mount_path }}"

    - name: "07 - Check if {{ dir_root }}{{ sps_install_filename }} exists on Remote-Machine in dir_rootectory"
      stat:
        path: "{{ dir_root }}{{ sps_install_filename }}"
      register: tar_details

    # - name: "07 - DEBUG"
    #   debug:
    #     msg: "{{ tar_details }}"

# Copy sps_install_filename from control-node to managed-nodes
    - name: "08 - Copy {{sps_install_filename}} from control-node to managed-hosts"
      copy:
        src: "{{dir_root}}{{sps_install_filename}}"
        dest: "{{dir_root}}{{sps_install_filename}}"
        mode: "0755"

    - name: "09 - Download Kernel-Devel"
      get_url:
        url: "http://mirror.centos.org/centos/8/BaseOS/x86_64/os/Packages/{{kernel_devel}}"
        dest: "{{ dir_root }}/{{kernel_devel}}"


    - name: "10 - Download Kernel-Header"
      get_url:
        url: "http://mirror.centos.org/centos/8/BaseOS/x86_64/os/Packages/kernel-headers-4.18.0-240.el8.x86_64.rpm"
        dest: "{{ dir_root }}/{{kernel_header}}"


    - name: "11 - Install Kernel Devel"
      yum:
        name: "{{ dir_root }}/{{kernel_devel}}"
        allow_downgrade: yes
        state: present
    - name: "12 - Install Kernel Header"
      yum:
        name: "{{ dir_root }}/{{kernel_header}}"
        allow_downgrade: yes
        state: present

# the epel-release must be removed for sps-prerequisites
    - name: "13 - Remove EPEL-Release-Repo"
      yum:
        name: "epel-release.noarch"
        state: "absent"

# Disable firewall for easier setup
    - name: "14 - Stop and disable firewalld"
      service:
        name: firewalld
        state: stopped
        enabled: "false"

# Execute the install-file to install the sps-dependencies
    - name: "15 - Execute SpectrumScale Install-File to extract gpfs-binaries, rpm-files, etc."
      raw: "{{ item }}"
      with_items:
        - "echo '1' | {{ dir_root }}{{ sps_install_filename }}"

# Execute the sps-setup only on one sps-node
    - name: "16 - Setup Spectrum-Scale-Installation-Node"
      raw: "{{ item }}"
      with_items:
        - "{{ spectrumscale_cmd }} setup -s {{ sps_setup_node_ip }} -i {{ private_root_key }}"
      when: "'{{ sps_node1 }}' in inventory_hostname"

# Configure the Spectrum-Scale-Cluster (make a config-file)
    # - name: "17 - Configure Spectrum-Scale"
    #   raw: "{{ item }}"
    #   with_items:
    #     - "{{ spectrumscale_cmd }} config gpfs -c {{ sps_cluster_name }}"
    #     - "{{ spectrumscale_cmd }} config ntp -e on -s {{ sps_ntp_ip1 }}"
    #     - "{{ spectrumscale_cmd }} config gpfs -e 60000-61000"
    #     - "{{ spectrumscale_cmd }} callhome disable"
    #     - "{{ spectrumscale_cmd }} config protocols -f {{ sps_filesystem_fs1 }} -m {{ sps_mountpoint_fs1 }}"
    #     - "{{ spectrumscale_cmd }} config protocols -f {{ sps_fs2 }} -m {{ sps_filesystem2 }}"
    #     - "{{ spectrumscale_cmd }} config protocols -e {{ sps_ces_export_ip1 }}"
    #     - "{{ spectrumscale_cmd }} enable smb nfs"
    #     - "{{ spectrumscale_cmd }} config protocols -l"
    #     - "{{ spectrumscale_cmd }} node add {{ sps_node1 }} -amnpq"
    #     - "{{ spectrumscale_cmd }} node add {{ sps_node2 }} -amnpq"
    #     - "{{ spectrumscale_cmd }} node add {{ sps_node3 }} -amnpqg"
    #     - "{{ spectrumscale_cmd }} nsd add -p {{ sps_node1 }} -fs {{ sps_filesystem_fs1 }} {{ sps_dev1 }}"
    #     - "{{ spectrumscale_cmd }} nsd add -p {{ sps_node2 }} -fs {{ sps_filesystem_fs1 }} {{ sps_dev1 }}"
    #     - "{{ spectrumscale_cmd }} nsd add -p {{ sps_node3 }} -fs {{ sps_filesystem_fs1 }} {{ sps_dev1 }}"
    #     - "{{ spectrumscale_cmd }} nsd add -p {{ sps_node1 }} -fs {{ sps_fs2 }} {{ sps_dev2 }}"
    #     - "{{ spectrumscale_cmd }} nsd add -p {{ sps_node2 }} -fs {{ sps_fs2 }} {{ sps_dev2 }}"
    #     - "{{ spectrumscale_cmd }} nsd add -p {{ sps_node3 }} -fs {{ sps_fs2 }} {{ sps_dev2 }}"
    #   when: "'{{ sps_node1 }}' in inventory_hostname"

# Install GPFS-Packages  
    - name: "18 - Install GPFS-RPM-Packages"
      yum:
        name:
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.base-5.1.0-3.x86_64.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.gskit-8.0.55-12.x86_64.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.license.std-5.1.0-3.x86_64.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.java-5.1.0-3.x86_64.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.gpl-5.1.0-3.noarch.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.docs-5.1.0-3.noarch.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/zimon_rpms/rhel8/gpfs.gss.pmsensors-5.1.0-3.el8.x86_64.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/zimon_rpms/rhel8/gpfs.gss.pmcollector-5.1.0-3.el8.x86_64.rpm"
          #- "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.protocols-support-5.1.0-3.noarch.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.msg.en_US-5.1.0-3.noarch.rpm"
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.compression-5.1.0-3.x86_64.rpm"
        state: "present"
      tags:
        - rpms

# Install GUI-Packages
    - name: "19 - Install GPFS-RPM-Packages for GUI-Node"
      yum:
        name:
          - "/usr/lpp/mmfs/5.1.0.3/gpfs_rpms/gpfs.gui-5.1.0-3.noarch.rpm"
        state: "present"
      when: "'{{ sps_node3 }}' in inventory_hostname"
      tags:
        - rpms

# Add PATH to bash_profile to execute GPFS-Commands from everywhere
    - name: "20 - Add Path /usr/lpp/mmfs/bin to bash_profile"
      lineinfile: 
        path: "/root/.bash_profile"
        regexp: "^PATH="
        line: "PATH=$PATH:$HOME/bin:/usr/lpp/mmfs/bin"
        state: "present"
      tags:
        - bash

# Building the GPFS portability layer on Linux nodes using mmbuildgpl 
    - name: "21 - Build the GPFS-Portability-Layer with mmbuildgpl"
      raw: "/usr/lpp/mmfs/bin/mmbuildgpl"
      tags:
        - gpl


# Disable the rpcbind-service and socket
    - name: "22 - Disable rpcbind-service as prereq from SPS"
      service:
        name: "rpcbind"
        enabled: "false"
        state: "stopped"
      tags:
        - retry
    - name: "23 - Disable rpcbind-socket as prereq from SPS"
      service:
        name: "rpcbind.socket"
        enabled: "false"
        state: "stopped"
      tags:
        - retry

# Create the cluster
    - name: "24 - Create the Cluster with mmcrcluster"
      raw: "/usr/lpp/mmfs/bin/mmcrcluster -N {{sps.sps1.fqdn}}:manager-quorum:{{sps.sps1.hostname}},{{sps.sps2.fqdn}}:manager:{{sps.sps2.hostname}},{{sps.sps3.fqdn}}:manager:{{sps.sps3.hostname}} -C {{sps_cluster_name}}"
      when: "'{{ sps_node1 }}' in inventory_hostname"

# Assign license to Nodes
    - name: "25 - Assign license with mmchlicense"
      raw: "/usr/lpp/mmfs/bin/mmchlicense server --accept -N {{sps.sps1.fqdn}},{{sps.sps2.fqdn}},{{sps.sps3.fqdn}}"
      when: "'{{ sps_node1 }}' in inventory_hostname"

      
# Starten des GPFS-CLusters
    - name: "26 - Start the GPFS-Cluster with mmstartup"
      raw: "/usr/lpp/mmfs/bin/mmstartup -a"
      when: "'{{ sps_node1 }}' in inventory_hostname"

# Starten der GUI
    - name: "27 - Start the GPFS-GUI"
      raw: "systemctl start gpfsgui"
      when: "'{{ sps_node3 }}' in inventory_hostname"

# Enable the pmcollector and pmsensor
    - name: "27 - Enable the pmcollectors and pmsensors"
      raw: "/usr/lpp/mmfs/bin/mmperfmon config generate --collectors {{sps.sps1.fqdn}},{{sps.sps2.fqdn}},{{sps.sps3.fqdn}}"
      when: "'{{ sps_node3 }}' in inventory_hostname"

# Create Stanza File from template
    - name: "28 - Create Stanza-File from template"
      template:
        src: "StanzaFile.j2"
        dest: "{{dir_root}}StanzaFile"
        mode: "0644"
      when: "'{{ sps_node1 }}' in inventory_hostname"


# Create NSDs for Cluster from Stanza File
    - name: "29 - Create NSDs for the Cluster with mmcrnsd"
      raw: "/usr/lpp/mmfs/bin/mmcrnsd -F {{dir_root}}StanzaFile"
      when: "'{{ sps_node1 }}' in inventory_hostname"

# Create Filesystem
    - name: "30 - Create Filesystem for the Cluster with mmcrnsd"
      raw: "/usr/lpp/mmfs/bin/mmcrfs spsopenshift -F {{dir_root}}StanzaFile -A yes -B 2M -j scatter -L 128M -n 2 -S relatime -r 2 -m 2 -T /mnt/spsopenshift -Q yes --filesetdf --perfileset-quota --inode-limit 2M:100K"
      when: "'{{ sps_node1 }}' in inventory_hostname"



# Mount Filesystems



